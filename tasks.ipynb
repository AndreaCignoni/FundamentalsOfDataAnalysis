{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Data Analysis Tasks\n",
    "\n",
    "**Andrea Cignoni**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "> The Collatz conjecture is a famous unsolved problem in mathematics. The problem is to prove that if you start with any positive integer $x$ and repeatedly apply the function $f(x)$ below, you always get stuck in the repeating sequence 1, 4, 2, 1, 4, 2, . . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function defines the calculation applied to the input number 'x'\n",
    "def f(x):\n",
    "    if x % 2 == 0: #This \"if\" clause checks whether the integer given is even or not\n",
    "        return x // 2 #If it is even it is devided by two\n",
    "    else:\n",
    "        return (3 * x) + 1 #If it is odd it then multiplied by 3 and then 1 is added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function formats the sequence of integers generated with the 'x' function\n",
    "def collatz (x):\n",
    "    while x != 1: #This 'while' clause stops the loop at number 1\n",
    "        print(x, end=', ')\n",
    "        x = f(x) # Update 'x' with the format defined in the collatz function\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collatz(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "> Give an overview of the famous penguins data set,2 explaining the types of variables it contains. Suggest the types of variables that should be used to model them in Python, explaining your rationale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# **PENGUINS DATA SET**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "The Palmer penguins dataset is a collection of data about penguins in the Palmer Archipelago, Antarctica. These data were collected from 2007 - 2009 by Dr. Kristen Gorman with the Palmer Station Long Term Ecological Research Program, part of the US Long Term Ecological Research Network and were collected on 344 penguins living on three islands (Torgersen, Biscoe, and Dream).<br/>\n",
    "\n",
    "The parameters considered are the followings:   \n",
    "\n",
    "\n",
    "+ Island name (Dream, Torgersen, or Biscoe);\n",
    "- Species name (Adelie, Chinstrap, or Gentoo);\n",
    "* Billl length (mm);\n",
    "+ Bill depth (mm);\n",
    "- Flipper length (mm);\n",
    "* Body mass (g);\n",
    "- Sex.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "![Screenshot](Penguins.png) ![Screenshot](Penguins1.png)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "**LOADING THE FILE AND LIBRARIES IMPORTED**<br/>\n",
    "\n",
    "The famous Palmer penguins dataset is downloaded from mwaskom/seaborn-data ![Github](https://github.com/mwaskom/). Since the information appears readable and structured just as the standard CSV tabular disposition (a comma separates individual items and each record is on a new line), I have proceeded to open it as such in my Python repository.\n",
    "\n",
    "Before proceeding to load the data in a data frame, I have proceeded to import the necessary modules to analyse all the variable represented in the file: Pandas; Matplotlib; Numpy; Seaborn.<br/>\n",
    "\n",
    "- Pandas\n",
    "\n",
    "Pandas is an open source Python package that is used for data science/data analysis and machine learning tasks. The common operations performed with Pandas are also: data cleansing, data fill, data normalization, merges and joins, data visualization, statistical analysis, data inspection, loading and saving data and much more. Here, I rely on Pandas for indexing the data frame, for manipulating it and extracting the sorted information from specified columns and rows. My main source for its usage is pandas.pydata.org\n",
    "\n",
    "- Matplotlib\n",
    "\n",
    "Matplotlib is a Python library used to create 2D graphs and plots through scripts. The pyplot module is explecially useful when it comes to control line styles, font properties, formatting axes etc. It supports a very wide variety of graphs and plots namely - histogram, bar charts, power spectra, error charts etc.\n",
    "\n",
    "- Numpy\n",
    "\n",
    "Matplotlib is used along with NumPy to provide an environment with an effective and fast numeric computing. Numpy furnishes a multidimensional array object and various derived objects (such as masked arrays and matrices).\n",
    "\n",
    "- Seaborn\n",
    "\n",
    "Lastly, in order to clearly display a graphic overview of the whole dataset through pair plots, I have imported Seaborn. This library is built on top of the Matplotlib data visualization library and can perform the exploratory analysis that fits best to show the result of my searches.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Extracting penguin dataset's 7 variables for data representation\n",
    "# File downloaded from (https://github.com/mwaskom/seaborn-data/blob/master/penguins.csv)\n",
    "\n",
    "data = pd.read_csv('penguins.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "**DATA DESCRIPTION**\n",
    "\n",
    "In order to give a visual overview of the data contained in the dataset, I have utilised a number of functions provided by Pandas referring to realpython.com. As already pointed out, the observations of the penguins are classified through 8 classes of prameters.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Below are shown the first and the last five rows of the dataset\n",
      "    species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
      "0    Adelie  Torgersen            39.1           18.7              181.0   \n",
      "1    Adelie  Torgersen            39.5           17.4              186.0   \n",
      "2    Adelie  Torgersen            40.3           18.0              195.0   \n",
      "3    Adelie  Torgersen             NaN            NaN                NaN   \n",
      "4    Adelie  Torgersen            36.7           19.3              193.0   \n",
      "..      ...        ...             ...            ...                ...   \n",
      "339  Gentoo     Biscoe             NaN            NaN                NaN   \n",
      "340  Gentoo     Biscoe            46.8           14.3              215.0   \n",
      "341  Gentoo     Biscoe            50.4           15.7              222.0   \n",
      "342  Gentoo     Biscoe            45.2           14.8              212.0   \n",
      "343  Gentoo     Biscoe            49.9           16.1              213.0   \n",
      "\n",
      "     body_mass_g     sex  \n",
      "0         3750.0    MALE  \n",
      "1         3800.0  FEMALE  \n",
      "2         3250.0  FEMALE  \n",
      "3            NaN     NaN  \n",
      "4         3450.0  FEMALE  \n",
      "..           ...     ...  \n",
      "339          NaN     NaN  \n",
      "340       4850.0  FEMALE  \n",
      "341       5750.0    MALE  \n",
      "342       5200.0  FEMALE  \n",
      "343       5400.0    MALE  \n",
      "\n",
      "[344 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\",\"Below are shown the first and the last five rows of the dataset\")\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " This is the summary of the dataframe, including information about the column names, data types, and non-null values: \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   bill_length_mm     342 non-null    float64\n",
      " 3   bill_depth_mm      342 non-null    float64\n",
      " 4   flipper_length_mm  342 non-null    float64\n",
      " 5   body_mass_g        342 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 18.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check the DataFrame structure\n",
    "print(\"\\n\",\"This is the summary of the dataframe, including information about the column names, data types, and non-null values:\",\"\\n\")\n",
    "\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " These are the main statistical information of the dataset: \n",
      "\n",
      "       bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n",
      "count      342.000000     342.000000         342.000000   342.000000\n",
      "mean        43.921930      17.151170         200.915205  4201.754386\n",
      "std          5.459584       1.974793          14.061714   801.954536\n",
      "min         32.100000      13.100000         172.000000  2700.000000\n",
      "25%         39.225000      15.600000         190.000000  3550.000000\n",
      "50%         44.450000      17.300000         197.000000  4050.000000\n",
      "75%         48.500000      18.700000         213.000000  4750.000000\n",
      "max         59.600000      21.500000         231.000000  6300.000000\n"
     ]
    }
   ],
   "source": [
    "# this function is to display stats about data\n",
    "print(\"\\n\",\"These are the main statistical information of the dataset:\",\"\\n\")\n",
    "\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Number of samples for each class: \n",
      "\n",
      "Adelie       152\n",
      "Gentoo       124\n",
      "Chinstrap     68\n",
      "Name: species, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of observation taken for each species\n",
    "print(\"\\n\",\"Number of samples for each class:\",\"\\n\")\n",
    "\n",
    "print(data['species'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "**PREPROCESSING THE DATA SET**\n",
    "\n",
    "\n",
    "Before proceeding to my actual analysis, I have preprocessed the data contained in the penguins dataset. This standard procedure is used to remove missing or inconsistent data values resulting from human or computer error. Preprocessing data can significantly improve the accuracy and quality of a dataset, making it more reliable. Once the data are proved to be consistent and all unhelpful parts are eliminated, the information can be transformed into a format that is more easily and effectively processed in data mining, machine learning and other data science tasks.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Below, the missing values that were found in the raw file: \n",
      "\n",
      "species               0\n",
      "island                0\n",
      "bill_length_mm        2\n",
      "bill_depth_mm         2\n",
      "flipper_length_mm     2\n",
      "body_mass_g           2\n",
      "sex                  11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing the dataset: check for null values\n",
    "print(\"\\n\",\"Below, the missing values that were found in the raw file:\",\"\\n\")\n",
    "\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "**DATA TYPES**\n",
    "\n",
    "the function used in Pandas to extract the types of data contained in the dataset is the *dtypes* attribute:\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\",\"The Penguins dataset containes 4 numerical variables and 3 categorical variables:\", \"\\n\")\n",
    "\n",
    "data_types = data.dtypes\n",
    "\n",
    "print(data_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "Once we have established which kind of data are being analysed, I can determine the graphical representation tequinques to compare and examine them best. My main point of reference for this topic is [Toward Science](https://towardsdatascience.com/penguins-dataset-overview-iris-alternative-9453bb8c8d95) website.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "# **TYPES OF VARIABLES IN THE DATASET**\n",
    "\n",
    "\n",
    "Variables can be *dependent* or *independent* and this basic discrimnation depends on their roles in an experiment or in a statistical study. This two classes can be further characterised and distinguished into *categoricals* or *continous*.\n",
    "\n",
    "1. *Dependent variable*: A dependent variable is a variable whose outcome or result depends on, or is influenced by, changes in its causes (called the independent variable) ==> **The dependent variable is often plotted on the y-axis of a graph**\n",
    "\n",
    "2. *Independent variable*: The independent variable is the variable that is intentionally changed or manipulated to observe its effect on the dependent variable ==> **The independent variable is often plotted on the x-axis of a graph**\n",
    "\n",
    "For instance, if a test mark can be considered a dependent variable and the many factors- such as the hours students spent in preparing the exam or their IQ level- can be considered independent variables: in fact, the scores are expected to be different if these causes are somehow modified. In data analysis, examinig how the dependent variables vary when their independent variables are manipulated can uncover insights and it is essential to make meaningful conclusions about cause and effect relationships. If you're interested in exploring the relationship between two variables, it's common to represent the independent variable (the one you suspect influences the other) on the x-axis and the dependent variable (the one you suspect is influenced) on the y-axis. In this way, it is possible to highight how the changes in the x-axis variable affect the y-axis variable. Here, my main studies are based on the article titled [\"A Grahic Primer\"](https://mathbench.umd.edu/modules/visualization_graph/page02.htm#:~:text=Scientists%20like%20to%20say%20that,left%20side%2C%20vertical%20one) found on https://mathbench.umd.edu/index.html.\n",
    "\n",
    "As already mentioned, both dependent and independent variables can be categorized as either *categorical* or *continuous*. \n",
    "\n",
    "* *Categorical variables* are variables that represent qualitative characteristics or attributes ==> **In graphs, categorical variables are often represented using labels or names**\n",
    "\n",
    "In relation to the Palmer Penguins dataset, it is necessary to examine further two variants of categorical variables: *nominal* and *dichotomous* variables. A nominal variable is a type of categorical variable where the categories have no inherent order or ranking. In other words, the categories are simply labels without any specific value or hierarchy associated with them. A dichotomous variable is a type of categorical variable that has only two possible categories or outcomes. These categories are typically labeled as \"yes\" or \"no,\" \"true\" or \"false,\" or \"0\" and \"1\".\n",
    "\n",
    "In our case, the *species* and the *islands* are nominal categorical variables while the *sex* is a dichotomous variable:\n",
    "\n",
    "  - Species: It represents the species of penguins such as Adelie, Chinstrap, or Gentoo. As already seen, Python interpreter reads the column where their are stored as a string data type, as each species name is a label or category.\n",
    "   \n",
    "   - Island: It represents the island where the penguin was observed, such as Torgersen, Biscoe, or Dream. Since these island names are also categories, they can be also represented using Python's string data type.\n",
    "   \n",
    "   - Sex: It represents the gender of the penguin that can be either male or female. The sex variable can be represented using Python's string data type or using a binary variable (0 for male, 1 for female) using Python's integer ( for instance 0 or 1) or boolean data types.\n",
    "\n",
    "\n",
    "* *Continuous variables*: Continuous variables are variables that represent numerical quantities and can take on any value within a certain range. They are typically measured on a continuous scale. Continuous variables are characterized by having an infinite number of possible values between any two values. Examples of continuous variables include height, weight, temperature, and time. \n",
    "\n",
    "In the Palmer Penguin dataset, the continuous variables are *bill length*, *bill depth*, *flipper length* and *body mass* and they are expressed in numbers, namely millimiters and grams. For numerical variables, you can use Python's float data type (float) or integer data type (int) to represent the measurements. Use float if you want to preserve decimal places in the values, or use int if the measurements are whole numbers only.\n",
    "\n",
    "To understand the different types of variables, I have used as source of information [Laerd website](https://statistics.laerd.com/statistical-guides/types-of-variable.php/).\n",
    "\n",
    "\n",
    "**What are then the dependent variables that we should focus on when using the different independent variables?**\n",
    "\n",
    "Obviously the elements in the dataset that can vary when the other attributes are differently combined are the penguins' species and our aim can be to establish a principle that can be used to predict what is the specific dependent categorical variable if we have a minimum set of independent variables.\n",
    "\n",
    "Once identified which viariables are stored in our dataset and my target, the next step would be using the peculiarities of each species.\n",
    "\n",
    "In order to achieve a clear portrait of the species of penguins, we can use the dataframe to depict and come to assumptions using the independent variables that characterise each dependent variable. Specifically, we can answer the three following questions:\n",
    "\n",
    "1. How are the three penguins' species distributed over each island?\n",
    "\n",
    "2. What is the difference in mesurements between the three different species?\n",
    "\n",
    "3. Is there any specific characteristic that distinguishes more one species from the others?\n",
    "\n",
    "When this description is fully deployed, we can pass to compare and build relationships between the species and try to find a possible linear border of discrimination which allows to draw the minimum conditions we can predict what dependent variable we are examining with a given set of independent parameters.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
